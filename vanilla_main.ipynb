{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from VanillaTransformer import VanillaTransformer, CustomDataSet, model_tuning\n",
    "from config import SAMPLE_SIZE_BY_SEQ_LENGTH, MAX_SEQ_LENGTH, VOCAB_SIZE, RANDOM_STATE\n",
    "from model_utils import print_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_by_seq_length = SAMPLE_SIZE_BY_SEQ_LENGTH\n",
    "max_seq_length = MAX_SEQ_LENGTH     # also a parameter for the transformer model\n",
    "vocab_size = VOCAB_SIZE             # also a parameter for the transformer model\n",
    "random_state = RANDOM_STATE\n",
    "\n",
    "dataset = CustomDataSet(\n",
    "    sample_size_by_seq_length,\n",
    "    max_seq_length,\n",
    "    vocab_size,\n",
    "    random_state\n",
    ")\n",
    "\n",
    "# Split dataset into 20% training, 10% validation and 70% test\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.8, random_state=random_state)\n",
    "\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.875, random_state=random_state)\n",
    "\n",
    "batch_size = 8\n",
    "train_data_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "\n",
    "input_val = torch.stack([row[0] for row in val_data])\n",
    "target_val = torch.stack([row[1] for row in val_data])\n",
    "\n",
    "input_test = torch.stack([row[0] for row in test_data])\n",
    "target_test = torch.stack([row[1] for row in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train dataset size\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([5, 6, 1, 0, 0]), tensor([10,  1,  6,  5,  0,  0])),\n",
       " (tensor([8, 8, 3, 4, 9]), tensor([10,  9,  4,  3,  8,  8])),\n",
       " (tensor([5, 9, 4, 1, 1]), tensor([10,  1,  1,  4,  9,  5])),\n",
       " (tensor([4, 2, 2, 8, 0]), tensor([10,  8,  2,  2,  4,  0])),\n",
       " (tensor([4, 5, 4, 5, 9]), tensor([10,  9,  5,  4,  5,  4])),\n",
       " (tensor([9, 7, 2, 8, 5]), tensor([10,  5,  8,  2,  7,  9]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train dataset example\n",
    "train_data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation dataset size\n",
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([4, 4, 5, 1, 1]), tensor([10,  1,  1,  5,  4,  4])),\n",
       " (tensor([6, 8, 5, 8, 2]), tensor([10,  2,  8,  5,  8,  6])),\n",
       " (tensor([1, 2, 9, 1, 5]), tensor([10,  5,  1,  9,  2,  1])),\n",
       " (tensor([5, 3, 2, 9, 4]), tensor([10,  4,  9,  2,  3,  5])),\n",
       " (tensor([8, 9, 9, 3, 9]), tensor([10,  9,  3,  9,  9,  8])),\n",
       " (tensor([1, 1, 3, 4, 1]), tensor([10,  1,  4,  3,  1,  1]))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation dataset example\n",
    "val_data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3495"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dataset size\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([6, 6, 1, 5, 3]), tensor([10,  3,  5,  1,  6,  6])),\n",
       " (tensor([7, 4, 8, 5, 8]), tensor([10,  8,  5,  8,  4,  7])),\n",
       " (tensor([4, 6, 6, 5, 5]), tensor([10,  5,  5,  6,  6,  4])),\n",
       " (tensor([9, 2, 3, 1, 0]), tensor([10,  1,  3,  2,  9,  0])),\n",
       " (tensor([8, 8, 4, 3, 0]), tensor([10,  3,  4,  8,  8,  0])),\n",
       " (tensor([5, 1, 3, 8, 1]), tensor([10,  1,  8,  3,  1,  5]))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dataset example\n",
    "test_data[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/Vanilla Transformer.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = vocab_size + 1  # adding padding token 0\n",
    "tgt_vocab_size = vocab_size + 2  # adding padding token 0 and start of sequence token (which is 10 in this case)\n",
    "embed_dim = 512\n",
    "max_seq_length = max_seq_length\n",
    "n_heads = 8\n",
    "n_layers = 1\n",
    "d_ff = 2048\n",
    "dropout_rate = 0.1\n",
    "\n",
    "model = VanillaTransformer(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    max_seq_length=max_seq_length,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    d_ff=d_ff,\n",
    "    dropout_rate=dropout_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model on train dataset and use cross entropy loss as objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.8096758127212524\n",
      "Epoch: 2, Loss: 1.411741018295288\n",
      "Epoch: 3, Loss: 0.7652240991592407\n",
      "Epoch: 4, Loss: 0.8128155469894409\n",
      "Epoch: 5, Loss: 0.5295798182487488\n",
      "Epoch: 6, Loss: 0.5216532349586487\n",
      "Epoch: 7, Loss: 0.21543781459331512\n",
      "Epoch: 8, Loss: 0.2492685616016388\n",
      "Epoch: 9, Loss: 0.2534533441066742\n",
      "Epoch: 10, Loss: 0.2330797016620636\n",
      "Epoch: 11, Loss: 0.2787517309188843\n",
      "Epoch: 12, Loss: 0.09256324917078018\n",
      "Epoch: 13, Loss: 0.2796880900859833\n",
      "Epoch: 14, Loss: 0.10518288612365723\n",
      "Epoch: 15, Loss: 0.10468956083059311\n",
      "Epoch: 16, Loss: 0.08435027301311493\n",
      "Epoch: 17, Loss: 0.06962082535028458\n",
      "Epoch: 18, Loss: 0.10666897892951965\n",
      "Epoch: 19, Loss: 0.03471643105149269\n",
      "Epoch: 20, Loss: 0.14675766229629517\n"
     ]
    }
   ],
   "source": [
    "train_loss = model.model_training(train_data_loader, epochs=20, lr=1e-5, print_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the model on test dataset, and report the cross entropy loss.<br>\n",
    "Besides, we also report prediction accuracy on token and sequence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.23524387180805206\n"
     ]
    }
   ],
   "source": [
    "out_test, loss = model.model_eval(input_test, target_test)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 5, 1, 6, 6],\n",
       "        [8, 5, 8, 4, 7],\n",
       "        [5, 5, 6, 6, 4],\n",
       "        ...,\n",
       "        [5, 8, 3, 9, 0],\n",
       "        [2, 1, 8, 9, 4],\n",
       "        [1, 4, 6, 5, 4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target sequences\n",
    "target_test[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 5, 1, 6, 6],\n",
       "        [8, 5, 8, 4, 7],\n",
       "        [5, 5, 6, 4, 6],\n",
       "        ...,\n",
       "        [5, 8, 3, 9, 0],\n",
       "        [2, 1, 8, 9, 4],\n",
       "        [1, 4, 6, 5, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted sequences\n",
    "pred_test = torch.argmax(out_test, dim=-1)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report accuracy on token level\n",
      "Number of wrong token predictions: 1072\n",
      "Number of total token predictions: 17475\n",
      "Token Accuracy: 93.8655%\n",
      "\n",
      "Report accuracy on sequence level\n",
      "Number of wrong sequence predictions: 580\n",
      "Number of total sequence predictions: 3495\n",
      "Sequence Accuracy: 83.4049%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(pred_test, target_test[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use optuna and a validation dataset to tune the model for the following parameters (numbers in brackets are possible values):\n",
    "- embed_dim: [256, 512, 1024, 2048]\n",
    "- n_heads: [1, 2, 4, 8]\n",
    "- n_layers: [1, 2, 4]\n",
    "- d_ff = [512, 1024, 2048, 4096]\n",
    "- dropout_rate: [0, 0.1, 0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-30 14:15:15,943] A new study created in memory with name: no-name-33b67b67-7668-45da-a972-93d6b1691e9e\n",
      "[I 2024-01-30 14:16:16,033] Trial 0 finished with value: 0.00769601808860898 and parameters: {'embed_dim': 512, 'n_heads': 8, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:16:55,595] Trial 1 finished with value: 0.5076445937156677 and parameters: {'embed_dim': 2048, 'n_heads': 2, 'n_layers': 1, 'd_ff': 2048, 'dropout_rate': 0.3}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:17:39,273] Trial 2 finished with value: 0.051112718880176544 and parameters: {'embed_dim': 256, 'n_heads': 1, 'n_layers': 4, 'd_ff': 1024, 'dropout_rate': 0.1}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:18:06,390] Trial 3 finished with value: 0.3929946720600128 and parameters: {'embed_dim': 512, 'n_heads': 4, 'n_layers': 2, 'd_ff': 512, 'dropout_rate': 0.5}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:19:01,873] Trial 4 finished with value: 0.1469794660806656 and parameters: {'embed_dim': 512, 'n_heads': 8, 'n_layers': 4, 'd_ff': 2048, 'dropout_rate': 0.5}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:19:48,868] Trial 5 finished with value: 0.02544212155044079 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 2, 'd_ff': 4096, 'dropout_rate': 0.4}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:20:36,965] Trial 6 finished with value: 0.07587862759828568 and parameters: {'embed_dim': 256, 'n_heads': 4, 'n_layers': 4, 'd_ff': 1024, 'dropout_rate': 0.1}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:21:54,614] Trial 7 finished with value: 0.14361079037189484 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 4, 'd_ff': 2048, 'dropout_rate': 0.4}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:24:15,577] Trial 8 finished with value: 0.04832166060805321 and parameters: {'embed_dim': 2048, 'n_heads': 4, 'n_layers': 4, 'd_ff': 1024, 'dropout_rate': 0.2}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:26:30,221] Trial 9 finished with value: 0.1255253702402115 and parameters: {'embed_dim': 2048, 'n_heads': 2, 'n_layers': 4, 'd_ff': 512, 'dropout_rate': 0.1}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:26:48,633] Trial 10 finished with value: 0.2732506990432739 and parameters: {'embed_dim': 512, 'n_heads': 8, 'n_layers': 1, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:27:36,874] Trial 11 finished with value: 0.00950123555958271 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 2, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:28:25,349] Trial 12 finished with value: 0.00882148090749979 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 2, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:29:14,741] Trial 13 finished with value: 0.009951229207217693 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 2, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:29:48,229] Trial 14 finished with value: 0.0211012102663517 and parameters: {'embed_dim': 512, 'n_heads': 1, 'n_layers': 2, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:30:14,835] Trial 15 finished with value: 0.19240131974220276 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 1, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:30:48,000] Trial 16 finished with value: 0.04821104183793068 and parameters: {'embed_dim': 512, 'n_heads': 8, 'n_layers': 2, 'd_ff': 4096, 'dropout_rate': 0.3}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:31:16,001] Trial 17 finished with value: 0.1861986368894577 and parameters: {'embed_dim': 256, 'n_heads': 8, 'n_layers': 2, 'd_ff': 4096, 'dropout_rate': 0.2}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:32:03,965] Trial 18 finished with value: 0.04420680180191994 and parameters: {'embed_dim': 512, 'n_heads': 1, 'n_layers': 4, 'd_ff': 512, 'dropout_rate': 0}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:32:29,068] Trial 19 finished with value: 0.22514501214027405 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 1, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 0 with value: 0.00769601808860898.\n",
      "[I 2024-01-30 14:34:01,908] Trial 20 finished with value: 0.002519480651244521 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 20 with value: 0.002519480651244521.\n",
      "[I 2024-01-30 14:35:33,653] Trial 21 finished with value: 0.0035450926516205072 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 20 with value: 0.002519480651244521.\n",
      "[I 2024-01-30 14:37:06,926] Trial 22 finished with value: 0.028039226308465004 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 20 with value: 0.002519480651244521.\n",
      "[I 2024-01-30 14:38:42,196] Trial 23 finished with value: 0.003820694051682949 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 20 with value: 0.002519480651244521.\n",
      "[I 2024-01-30 14:40:35,671] Trial 24 finished with value: 0.003005772829055786 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0}. Best is trial 20 with value: 0.002519480651244521.\n",
      "[I 2024-01-30 14:42:11,435] Trial 25 finished with value: 0.002917523728683591 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0.2}. Best is trial 20 with value: 0.002519480651244521.\n",
      "[I 2024-01-30 14:43:25,695] Trial 26 finished with value: 0.10696392506361008 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 4, 'd_ff': 1024, 'dropout_rate': 0.2}. Best is trial 20 with value: 0.002519480651244521.\n",
      "[I 2024-01-30 14:44:43,187] Trial 27 finished with value: 0.038820780813694 and parameters: {'embed_dim': 1024, 'n_heads': 1, 'n_layers': 4, 'd_ff': 2048, 'dropout_rate': 0.2}. Best is trial 20 with value: 0.002519480651244521.\n",
      "[I 2024-01-30 14:45:51,790] Trial 28 finished with value: 0.04370666295289993 and parameters: {'embed_dim': 1024, 'n_heads': 4, 'n_layers': 4, 'd_ff': 512, 'dropout_rate': 0.2}. Best is trial 20 with value: 0.002519480651244521.\n",
      "[I 2024-01-30 14:47:23,843] Trial 29 finished with value: 0.1715846210718155 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0.3}. Best is trial 20 with value: 0.002519480651244521.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = model_tuning(\n",
    "    train_data_loader,\n",
    "    input_val,\n",
    "    target_val,\n",
    "    vocab_size,\n",
    "    max_seq_length,\n",
    "    epochs=10,\n",
    "    n_trials=30,\n",
    ")\n",
    "print(\"Best params: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Setup with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VanillaTransformer(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    embed_dim=best_params[\"embed_dim\"],\n",
    "    max_seq_length=max_seq_length,\n",
    "    n_heads=best_params[\"n_heads\"],\n",
    "    n_layers=best_params[\"n_layers\"],\n",
    "    d_ff=best_params[\"d_ff\"],\n",
    "    dropout_rate=best_params[\"dropout_rate\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6881987452507019\n",
      "Epoch: 2, Loss: 0.09694904834032059\n",
      "Epoch: 3, Loss: 0.025846531614661217\n",
      "Epoch: 4, Loss: 0.06201569363474846\n",
      "Epoch: 5, Loss: 0.011647971346974373\n",
      "Epoch: 6, Loss: 0.010680916719138622\n",
      "Epoch: 7, Loss: 0.00915051344782114\n",
      "Epoch: 8, Loss: 0.029451774433255196\n",
      "Epoch: 9, Loss: 0.009591045789420605\n",
      "Epoch: 10, Loss: 0.006056835874915123\n",
      "Epoch: 11, Loss: 0.0006256059277802706\n",
      "Epoch: 12, Loss: 0.00033966120099648833\n",
      "Epoch: 13, Loss: 0.00023254378174897283\n",
      "Epoch: 14, Loss: 0.0003041864256374538\n",
      "Epoch: 15, Loss: 0.00015704116958659142\n",
      "Epoch: 16, Loss: 0.00020535135990940034\n",
      "Epoch: 17, Loss: 0.0003366702585481107\n",
      "Epoch: 18, Loss: 0.00014765045489184558\n",
      "Epoch: 19, Loss: 0.00036267575342208147\n",
      "Epoch: 20, Loss: 0.00020857652998529375\n"
     ]
    }
   ],
   "source": [
    "train_loss = model.model_training(train_data_loader, epochs=20, lr=1e-5, print_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0010492849396541715\n"
     ]
    }
   ],
   "source": [
    "out_test, loss = model.model_eval(input_test, target_test)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 5, 1, 6, 6],\n",
       "        [8, 5, 8, 4, 7],\n",
       "        [5, 5, 6, 6, 4],\n",
       "        ...,\n",
       "        [5, 8, 3, 9, 0],\n",
       "        [2, 1, 8, 9, 4],\n",
       "        [1, 4, 6, 5, 4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target sequences\n",
    "target_test[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 5, 1, 6, 6],\n",
       "        [8, 5, 8, 4, 7],\n",
       "        [5, 5, 6, 6, 4],\n",
       "        ...,\n",
       "        [5, 8, 3, 9, 0],\n",
       "        [2, 1, 8, 9, 4],\n",
       "        [1, 4, 6, 5, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted sequences\n",
    "pred_test = torch.argmax(out_test, dim=-1)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report accuracy on token level\n",
      "Number of wrong token predictions: 2\n",
      "Number of total token predictions: 17475\n",
      "Token Accuracy: 99.9886%\n",
      "\n",
      "Report accuracy on sequence level\n",
      "Number of wrong sequence predictions: 2\n",
      "Number of total sequence predictions: 3495\n",
      "Sequence Accuracy: 99.9428%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(pred_test, target_test[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "We referenced the implementation of the vanilla transformer from [datacamp](https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
