{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from CustomDataSet import CustomDataSet\n",
    "from Transformer import Transformer\n",
    "from config import SAMPLE_SIZE_BY_SEQ_LENGTH, MAX_SEQ_LENGTH, VOCAB_SIZE, RANDOM_STATE\n",
    "from model_utils import model_training, model_eval, model_tuning, print_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, we randomly generate data using class CustomDataSet. It takes three important parameters:\n",
    "- sample_size_by_seq_length: dict[seq_length: sample_size]\n",
    "\n",
    "    This is a dictionary where a key is a sequence length and its value is the number of sequences to be generated by that sequence length. <br>\n",
    "    Example: {1: 4, 2: 20, 3: 100, 4: 400, 5: 1000}\n",
    "\n",
    "- max_seq_length: int\n",
    "\n",
    "    the maximum length of each sequence\n",
    "\n",
    "- vocab_size: int\n",
    "\n",
    "    the size of vocabulary to be generated\n",
    "\n",
    "Each input sequence will be randomly generated given a specific length and consists of integers from 1 to <i>vocab_size</i>. Its corresponding target will be its reverse. <br>\n",
    "If an input sequence and its target have length < <i>max_seq_length</i>, it will be padded with 0s at the end so that all inputs and outputs will have length = <i>max_seq_length</i>. <br>\n",
    "Duplicated input generations will also be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_by_seq_length = SAMPLE_SIZE_BY_SEQ_LENGTH\n",
    "max_seq_length = MAX_SEQ_LENGTH     # also a parameter for the transformer model\n",
    "vocab_size = VOCAB_SIZE             # also a parameter for the transformer model\n",
    "random_state = RANDOM_STATE\n",
    "\n",
    "dataset = CustomDataSet(\n",
    "    sample_size_by_seq_length,\n",
    "    max_seq_length,\n",
    "    vocab_size,\n",
    "    random_state\n",
    ")\n",
    "\n",
    "# Split dataset into 20% training, 10% validation and 70% test\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.8, random_state=random_state)\n",
    "\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.875, random_state=random_state)\n",
    "\n",
    "batch_size = 8\n",
    "train_data_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "\n",
    "input_val = torch.stack([row[0] for row in val_data])\n",
    "target_val = torch.stack([row[1] for row in val_data])\n",
    "\n",
    "input_test = torch.stack([row[0] for row in test_data])\n",
    "target_test = torch.stack([row[1] for row in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train dataset size\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([5, 6, 1, 0, 0]), tensor([1, 6, 5, 0, 0])),\n",
       " (tensor([8, 8, 3, 4, 9]), tensor([9, 4, 3, 8, 8])),\n",
       " (tensor([5, 9, 4, 1, 1]), tensor([1, 1, 4, 9, 5])),\n",
       " (tensor([4, 2, 2, 8, 0]), tensor([8, 2, 2, 4, 0])),\n",
       " (tensor([4, 5, 4, 5, 9]), tensor([9, 5, 4, 5, 4])),\n",
       " (tensor([9, 7, 2, 8, 5]), tensor([5, 8, 2, 7, 9]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train dataset example\n",
    "train_data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation dataset size\n",
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([4, 4, 5, 1, 1]), tensor([1, 1, 5, 4, 4])),\n",
       " (tensor([6, 8, 5, 8, 2]), tensor([2, 8, 5, 8, 6])),\n",
       " (tensor([1, 2, 9, 1, 5]), tensor([5, 1, 9, 2, 1])),\n",
       " (tensor([5, 3, 2, 9, 4]), tensor([4, 9, 2, 3, 5])),\n",
       " (tensor([8, 9, 9, 3, 9]), tensor([9, 3, 9, 9, 8])),\n",
       " (tensor([1, 1, 3, 4, 1]), tensor([1, 4, 3, 1, 1]))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation dataset example\n",
    "val_data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3495"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dataset size\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([6, 6, 1, 5, 3]), tensor([3, 5, 1, 6, 6])),\n",
       " (tensor([7, 4, 8, 5, 8]), tensor([8, 5, 8, 4, 7])),\n",
       " (tensor([4, 6, 6, 5, 5]), tensor([5, 5, 6, 6, 4])),\n",
       " (tensor([9, 2, 3, 1, 0]), tensor([1, 3, 2, 9, 0])),\n",
       " (tensor([8, 8, 4, 3, 0]), tensor([3, 4, 8, 8, 0])),\n",
       " (tensor([5, 1, 3, 8, 1]), tensor([1, 8, 3, 1, 5]))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dataset example\n",
    "test_data[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](<Encoder-only Transformer.png>)\n",
    "\n",
    "The transformer has the following parameters:\n",
    "- src_vocab_size: int\n",
    "\n",
    "    Vocabulary size of the input\n",
    "\n",
    "- tgt_vocab_size: int\n",
    "\n",
    "    Vocabulary size of the output\n",
    "\n",
    "- embed_dim: int\n",
    "\n",
    "    A dimension of many layers of the transformer\n",
    "\n",
    "- max_seq_length: int\n",
    "\n",
    "    Maximum sequence length of an input\n",
    "\n",
    "- n_heads: int\n",
    "\n",
    "    Number of attention heads\n",
    "\n",
    "- n_layers: int\n",
    "\n",
    "    Number of encoder layers\n",
    "\n",
    "- d_ff: int\n",
    "\n",
    "    Dimension of the inner layer of the feed forward component\n",
    "\n",
    "- dropout_rate: float\n",
    "\n",
    "    Dropout rate applied on output of self attention and feed forward component\n",
    "\n",
    "- apply_mask: bool\n",
    "\n",
    "    Whether to apply mask on the input. If True, a token in the input sequence will only attend to non-padding tokens including itself. If False, it will attend to every token including padding tokens in the sequence.\n",
    "\n",
    "#### 1. Input\n",
    "Input is sequence of integers. Example: [3, 5, 4, 2, 1].\n",
    "\n",
    "#### 2. Embedding Layer\n",
    "If the input sequence has length < <i>max_seq_length</i>, pad 0s at the end. <br>\n",
    "Embed each integer in the sequence into a vector of dimension <i>embed_dim</i>.\n",
    "\n",
    "#### 3. Positional Encoding\n",
    "Encode each position from 0 to <i>max_seq_length-1</i> into a vector of dimension <i>embed_dim</i>.\n",
    "The positional encoding is fixed and calculated by the following formula:\n",
    "\n",
    "$$PE(pos, 2i) = sin(\\frac {pos} {10000^{\\frac {2i} {embed\\_dim}}})$$\n",
    "$$PE(pos, 2i+1) = cos(\\frac {pos} {10000^{\\frac {2i} {embed\\_dim}}})$$\n",
    "\n",
    "where pos = 0,..., max_seq_length and i = 0,..., embed_dim // 2\n",
    "\n",
    "The output after the positional encoding layer is the sum of the output of the embedding layer and the positional encoding.\n",
    "\n",
    "#### 4. Encoder Block\n",
    "\n",
    "Each encoder block consists of four components: multihead attention layer, first normalization layer, feed forward layer, and second normalization layer. <br>\n",
    "Encoder block can be duplicated as specified by parameter <i>n_layers</i>.\n",
    "\n",
    "##### 4.1 Multihead Attention\n",
    "Purpose: the tokens within a sequence can have multiple relationships with each other at the same time. By using multihead attention, we try to capture those different relationships.\n",
    "\n",
    "The multihead attention takes in three parameters:\n",
    "- $X_q$: matrix to be projected into a query matrix by multiplying with the learned matrix $W^Q$\n",
    "- $X_q$: matrix to be projected into a key matrix by multiplying with the learned matrix $W^K$\n",
    "- $X_v$: matrix to be projected into a value matrix by multiplying with the learned matrix $W^V$\n",
    "\n",
    "In the encoder block, all these three parameters are the same and equal to the output after the positional encoding layer.\n",
    "\n",
    "<b>How multihead attention is calculated in theory</b> <br>\n",
    "Let <i>X</i> be the output after the positional encoding layer. <br>\n",
    "Each attention head has a unique set of learned matrices $W_i^Q$, $W_i^K$, $W_i^V$ which is used to project $Q_i$, $K_i$, and $V_i$ as follows:\n",
    "\n",
    "$$Q_i = W_i^QX$$\n",
    "$$K_i = W_i^KX$$\n",
    "$$V_i = W_i^VX$$\n",
    "\n",
    "Attention score is calculated for each head (mask will be applied if parameter <i>apply_mask=True</i>):\n",
    "$$Attention Score_i = softmax(\\frac {Q_i K_i^T} {\\sqrt {embed\\_dim}})V_i$$\n",
    "\n",
    "Then the attention scores of all attention heads at are concatenated into one single matrix to be fed to the next layer.\n",
    "\n",
    "##### 4.2. Normalization 1\n",
    "The output of multihead attention and of positional encoding layer are added together and fed into a normalization layer. <br>\n",
    "To prevent overfitting, dropout with <i>dropout_rate</i> is applied on the multihead attention layer's output.\n",
    "\n",
    "##### 4.3. Feed Forward\n",
    "The feed forward component consists of:\n",
    "- a linear layer with dimension <i>d_ff</i> and ReLU activation\n",
    "- a linear layer with dimension <i>embed_dim</i>.\n",
    "\n",
    "##### 4.4. Normalization 2\n",
    "The output of feed forward layer and of the first normalization layer are added together and fed into a second normalization layer. <br>\n",
    "To prevent overfitting, dropout with <i>dropout_rate</i> is applied on the feed forward layer's output.\n",
    "\n",
    "#### 5. Linear Layer\n",
    "A linear layer that transforms the dimension of the output from encoder block from <i>embed_dim</i> to <i>target_vocab_size</i>.\n",
    "\n",
    "#### 6. Softmax\n",
    "Apply softmax function to get the probability of each token in the target vocabulary. <br>\n",
    "\n",
    "#### Summary\n",
    "The transformer has:\n",
    "- input: a sequence of integers. Dimension: <i>[seq_length]</i>.\n",
    "- output: probability distribution over the target vocabulary for each token in the output sequence. Dimension: <i>[max_seq_length, target_vocab_size]</i>.\n",
    "\n",
    "Note: in the actual implementation, we do not apply softmax function because when we use pytorch's CrossEntropyLoss() to calculate the loss and pytorch's CrossEntropyLoss() already applies softmax function before calculating the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = vocab_size + 1  # adding padding token 0\n",
    "tgt_vocab_size = vocab_size + 1\n",
    "embed_dim = 512\n",
    "max_seq_length = max_seq_length\n",
    "n_heads = 8\n",
    "n_layers = 1\n",
    "d_ff = 2048\n",
    "dropout_rate = 0.1\n",
    "apply_mask = False\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    max_seq_length=max_seq_length,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    d_ff=d_ff,\n",
    "    dropout_rate=dropout_rate,\n",
    "    apply_mask=apply_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model on train dataset and use cross entropy loss as objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.8463116884231567\n",
      "Epoch: 2, Loss: 1.626831293106079\n",
      "Epoch: 3, Loss: 1.5165215730667114\n",
      "Epoch: 4, Loss: 1.4740955829620361\n",
      "Epoch: 5, Loss: 0.9810271859169006\n",
      "Epoch: 6, Loss: 1.03404700756073\n",
      "Epoch: 7, Loss: 0.9466716647148132\n",
      "Epoch: 8, Loss: 1.0530587434768677\n",
      "Epoch: 9, Loss: 0.9262719750404358\n",
      "Epoch: 10, Loss: 0.7325530648231506\n",
      "Epoch: 11, Loss: 0.7900456190109253\n",
      "Epoch: 12, Loss: 0.7403037548065186\n",
      "Epoch: 13, Loss: 0.6354010701179504\n",
      "Epoch: 14, Loss: 0.6442050337791443\n",
      "Epoch: 15, Loss: 0.6760815978050232\n",
      "Epoch: 16, Loss: 0.7348865866661072\n",
      "Epoch: 17, Loss: 0.5840985774993896\n",
      "Epoch: 18, Loss: 0.5459777116775513\n",
      "Epoch: 19, Loss: 0.6845058798789978\n",
      "Epoch: 20, Loss: 0.6582540273666382\n"
     ]
    }
   ],
   "source": [
    "train_loss = model_training(model, train_data_loader, epochs=20, lr=1e-5, print_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the model on test dataset, and report the cross entropy loss.<br>\n",
    "Besides, we also report prediction accuracy on token and sequence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7026675939559937\n"
     ]
    }
   ],
   "source": [
    "out_test, loss = model_eval(model, input_test, target_test)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 5, 1, 6, 6],\n",
       "        [8, 5, 8, 4, 7],\n",
       "        [5, 5, 6, 6, 4],\n",
       "        ...,\n",
       "        [5, 8, 3, 9, 0],\n",
       "        [2, 1, 8, 9, 4],\n",
       "        [1, 4, 6, 5, 4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target sequences\n",
    "target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 1, 6, 6],\n",
       "        [8, 8, 8, 7, 7],\n",
       "        [5, 5, 6, 6, 4],\n",
       "        ...,\n",
       "        [5, 5, 8, 9, 0],\n",
       "        [2, 1, 8, 9, 4],\n",
       "        [1, 4, 4, 4, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted sequences\n",
    "pred_test = torch.argmax(out_test, dim=-1)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report accuracy on token level\n",
      "Number of wrong token predictions: 5657\n",
      "Number of total token predictions: 17475\n",
      "Token Accuracy: 67.6280%\n",
      "\n",
      "Report accuracy on sequence level\n",
      "Number of wrong sequence predictions: 3251\n",
      "Number of total sequence predictions: 3495\n",
      "Sequence Accuracy: 6.9814%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(pred_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use optuna and a validation dataset to tune the model for the following parameters (numbers in brackets are possible values):\n",
    "- embed_dim: [256, 512, 1024, 2048]\n",
    "- n_heads: [1, 2, 4, 8]\n",
    "- n_layers: [1, 2, 4, 8]\n",
    "- d_ff = [512, 1024, 2048, 4096]\n",
    "- dropout_rate: [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "- apply_mask : [True, False]\n",
    "\n",
    "We observe that the most impactful parameter is the number of encoders (<i>n_layers</i>). When <i>n_layers = 1</i>, the accuracy on token level on the test dataset is about 66% after 20 training epochs. When <i>n_layers = 4</i>, the accuracy is over 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-01 08:30:57,987] A new study created in memory with name: no-name-7554c383-bc46-462d-9e13-ef2e100ec6b5\n",
      "[I 2023-12-01 08:31:19,182] Trial 0 finished with value: 0.7388737201690674 and parameters: {'embed_dim': 512, 'n_heads': 8, 'n_layers': 4, 'd_ff': 2048, 'dropout_rate': 0.4, 'apply_mask': True}. Best is trial 0 with value: 0.7388737201690674.\n",
      "[I 2023-12-01 08:31:48,557] Trial 1 finished with value: 0.7194119095802307 and parameters: {'embed_dim': 256, 'n_heads': 4, 'n_layers': 8, 'd_ff': 1024, 'dropout_rate': 0, 'apply_mask': True}. Best is trial 1 with value: 0.7194119095802307.\n",
      "[I 2023-12-01 08:31:54,399] Trial 2 finished with value: 1.208134651184082 and parameters: {'embed_dim': 256, 'n_heads': 2, 'n_layers': 1, 'd_ff': 1024, 'dropout_rate': 0.1, 'apply_mask': False}. Best is trial 1 with value: 0.7194119095802307.\n",
      "[I 2023-12-01 08:32:13,287] Trial 3 finished with value: 1.0199381113052368 and parameters: {'embed_dim': 256, 'n_heads': 4, 'n_layers': 4, 'd_ff': 1024, 'dropout_rate': 0.2, 'apply_mask': True}. Best is trial 1 with value: 0.7194119095802307.\n",
      "[I 2023-12-01 08:32:32,598] Trial 4 finished with value: 0.4247561991214752 and parameters: {'embed_dim': 2048, 'n_heads': 4, 'n_layers': 1, 'd_ff': 4096, 'dropout_rate': 0.5, 'apply_mask': False}. Best is trial 4 with value: 0.4247561991214752.\n",
      "[I 2023-12-01 08:32:40,475] Trial 5 finished with value: 0.8590657711029053 and parameters: {'embed_dim': 512, 'n_heads': 8, 'n_layers': 2, 'd_ff': 512, 'dropout_rate': 0.2, 'apply_mask': True}. Best is trial 4 with value: 0.4247561991214752.\n",
      "[I 2023-12-01 08:32:48,157] Trial 6 finished with value: 1.189160704612732 and parameters: {'embed_dim': 256, 'n_heads': 4, 'n_layers': 2, 'd_ff': 2048, 'dropout_rate': 0.5, 'apply_mask': True}. Best is trial 4 with value: 0.4247561991214752.\n",
      "[I 2023-12-01 08:32:54,867] Trial 7 finished with value: 0.6124457716941833 and parameters: {'embed_dim': 1024, 'n_heads': 4, 'n_layers': 1, 'd_ff': 512, 'dropout_rate': 0.3, 'apply_mask': True}. Best is trial 4 with value: 0.4247561991214752.\n",
      "[I 2023-12-01 08:33:11,259] Trial 8 finished with value: 0.6162899136543274 and parameters: {'embed_dim': 512, 'n_heads': 1, 'n_layers': 4, 'd_ff': 1024, 'dropout_rate': 0.5, 'apply_mask': False}. Best is trial 4 with value: 0.4247561991214752.\n",
      "[I 2023-12-01 08:33:27,937] Trial 9 finished with value: 0.6032684445381165 and parameters: {'embed_dim': 256, 'n_heads': 4, 'n_layers': 4, 'd_ff': 4096, 'dropout_rate': 0.1, 'apply_mask': True}. Best is trial 4 with value: 0.4247561991214752.\n",
      "[I 2023-12-01 08:33:46,795] Trial 10 finished with value: 0.43526872992515564 and parameters: {'embed_dim': 2048, 'n_heads': 1, 'n_layers': 1, 'd_ff': 4096, 'dropout_rate': 0.5, 'apply_mask': False}. Best is trial 4 with value: 0.4247561991214752.\n",
      "[I 2023-12-01 08:34:05,794] Trial 11 finished with value: 0.36316734552383423 and parameters: {'embed_dim': 2048, 'n_heads': 1, 'n_layers': 1, 'd_ff': 4096, 'dropout_rate': 0.5, 'apply_mask': False}. Best is trial 11 with value: 0.36316734552383423.\n",
      "[I 2023-12-01 08:34:24,344] Trial 12 finished with value: 0.3471282422542572 and parameters: {'embed_dim': 2048, 'n_heads': 1, 'n_layers': 1, 'd_ff': 4096, 'dropout_rate': 0.5, 'apply_mask': False}. Best is trial 12 with value: 0.3471282422542572.\n",
      "[I 2023-12-01 08:34:42,934] Trial 13 finished with value: 0.3612839877605438 and parameters: {'embed_dim': 2048, 'n_heads': 1, 'n_layers': 1, 'd_ff': 4096, 'dropout_rate': 0.5, 'apply_mask': False}. Best is trial 12 with value: 0.3471282422542572.\n",
      "[I 2023-12-01 08:37:00,891] Trial 14 finished with value: 0.012823079712688923 and parameters: {'embed_dim': 2048, 'n_heads': 1, 'n_layers': 8, 'd_ff': 4096, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 14 with value: 0.012823079712688923.\n",
      "[I 2023-12-01 08:39:19,832] Trial 15 finished with value: 0.008200972341001034 and parameters: {'embed_dim': 2048, 'n_heads': 1, 'n_layers': 8, 'd_ff': 4096, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 15 with value: 0.008200972341001034.\n",
      "[I 2023-12-01 08:40:22,367] Trial 16 finished with value: 0.0006055465200915933 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 4096, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:41:25,124] Trial 17 finished with value: 0.00145529059227556 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 4096, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:42:15,025] Trial 18 finished with value: 0.0008092074422165751 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:43:05,041] Trial 19 finished with value: 0.001047670841217041 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:43:53,415] Trial 20 finished with value: 0.007175166625529528 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.4, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:44:42,425] Trial 21 finished with value: 0.008773456327617168 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:45:30,890] Trial 22 finished with value: 0.0006532706320285797 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:46:20,630] Trial 23 finished with value: 0.0007176839280873537 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:47:11,802] Trial 24 finished with value: 0.0015052113449200988 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:48:03,259] Trial 25 finished with value: 0.00544714042916894 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:48:15,036] Trial 26 finished with value: 0.4496558606624603 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 2, 'd_ff': 512, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:49:04,819] Trial 27 finished with value: 0.004658030346035957 and parameters: {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:49:52,685] Trial 28 finished with value: 0.016344446688890457 and parameters: {'embed_dim': 1024, 'n_heads': 8, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.3, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n",
      "[I 2023-12-01 08:50:23,835] Trial 29 finished with value: 1.0607377290725708 and parameters: {'embed_dim': 512, 'n_heads': 8, 'n_layers': 8, 'd_ff': 2048, 'dropout_rate': 0.4, 'apply_mask': False}. Best is trial 16 with value: 0.0006055465200915933.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'embed_dim': 1024, 'n_heads': 2, 'n_layers': 8, 'd_ff': 4096, 'dropout_rate': 0.3, 'apply_mask': False}\n"
     ]
    }
   ],
   "source": [
    "best_params = model_tuning(\n",
    "        train_data_loader,\n",
    "        input_val,\n",
    "        target_val,\n",
    "        vocab_size,\n",
    "        max_seq_length,\n",
    "        epochs=10,\n",
    "        n_trials=30,\n",
    "    )\n",
    "print(\"Best params: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Setup with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    embed_dim=best_params[\"embed_dim\"],\n",
    "    max_seq_length=max_seq_length,\n",
    "    n_heads=best_params[\"n_heads\"],\n",
    "    n_layers=best_params[\"n_layers\"],\n",
    "    d_ff=best_params[\"d_ff\"],\n",
    "    dropout_rate=best_params[\"dropout_rate\"],\n",
    "    apply_mask=best_params[\"apply_mask\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.5765845775604248\n",
      "Epoch: 2, Loss: 1.2758125066757202\n",
      "Epoch: 3, Loss: 0.7459736466407776\n",
      "Epoch: 4, Loss: 0.4431268274784088\n",
      "Epoch: 5, Loss: 0.1554466187953949\n",
      "Epoch: 6, Loss: 0.013323682360351086\n",
      "Epoch: 7, Loss: 0.007814707234501839\n",
      "Epoch: 8, Loss: 0.005584456026554108\n",
      "Epoch: 9, Loss: 0.0032332586124539375\n",
      "Epoch: 10, Loss: 0.0023247019853442907\n",
      "Epoch: 11, Loss: 0.0026821154169738293\n",
      "Epoch: 12, Loss: 0.0014540167758241296\n",
      "Epoch: 13, Loss: 0.17802949249744415\n",
      "Epoch: 14, Loss: 0.004901160020381212\n",
      "Epoch: 15, Loss: 0.13879482448101044\n",
      "Epoch: 16, Loss: 0.002519606612622738\n",
      "Epoch: 17, Loss: 0.0016682054847478867\n",
      "Epoch: 18, Loss: 0.0019328116904944181\n",
      "Epoch: 19, Loss: 0.0010821718024089932\n",
      "Epoch: 20, Loss: 0.0009244779357686639\n"
     ]
    }
   ],
   "source": [
    "train_loss = model_training(model, train_data_loader, epochs=20, lr=1e-5, print_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.00011462868860689923\n"
     ]
    }
   ],
   "source": [
    "out_test, loss = model_eval(model, input_test, target_test)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 5, 1, 6, 6],\n",
       "        [8, 5, 8, 4, 7],\n",
       "        [5, 5, 6, 6, 4],\n",
       "        ...,\n",
       "        [5, 8, 3, 9, 0],\n",
       "        [2, 1, 8, 9, 4],\n",
       "        [1, 4, 6, 5, 4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target sequences\n",
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 5, 1, 6, 6],\n",
       "        [8, 5, 8, 4, 7],\n",
       "        [5, 5, 6, 6, 4],\n",
       "        ...,\n",
       "        [5, 8, 3, 9, 0],\n",
       "        [2, 1, 8, 9, 4],\n",
       "        [1, 4, 6, 5, 4]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted sequences\n",
    "pred_test = torch.argmax(out_test, dim=-1)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report accuracy on token level\n",
      "Number of wrong token predictions: 0\n",
      "Number of total token predictions: 17475\n",
      "Token Accuracy: 100.0000%\n",
      "\n",
      "Report accuracy on sequence level\n",
      "Number of wrong sequence predictions: 0\n",
      "Number of total sequence predictions: 3495\n",
      "Sequence Accuracy: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(pred_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "We referenced the implementation of the vanilla transformer from [datacamp](https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
